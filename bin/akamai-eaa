#!/usr/bin/env python

# Copyright 2020 Akamai Technologies, Inc. All Rights Reserved
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Load Akamai Enteprise Application Access access logs
# Original author: <androcho@akamai.com> based on Splunk app

from __future__ import print_function
import os
import sys
import json
import requests
import time
import base64
import hmac
import hashlib
import platform
from datetime import datetime
import logging
import signal
from threading import Event
import six

from config import EdgeGridConfig

# If all parameters are set already, use them.  Otherwise
# use the config
config = EdgeGridConfig({"verbose": False}, "default")
verbose = getattr(config, "verbose", False)

SOURCE = "akamai-cli/eaa"
LOG_TYPE_EVENT = "access"
LOG_TYPE_ADMIN = "admin"
ADMINEVENT_API = "{}/api/{}/adminevents-reports/ops/splunk-query"
ACCESSLOG_API = "{}/api/{}/analytics/ops"
LOG = logging.getLogger(__name__)

datef = "%Y-%m-%d %H:%M"
collection_delay_minutes = 1
log_file = None
poll_interval_sec = 15
line_count = 0
stop_event = Event()


class Etl(object):
    """ETL"""

    def __init__(self, api_version='v1'):
        self._api_ver = api_version
        self._content_type_json = {'content-type': 'application/json'}
        self._content_type_form = {'content-type': 'application/x-www-form-urlencoded'}
        self._headers = None

    def get_signature(self, access_key_id, secret_access_key):
        encoding = 'ascii'
        msg = "%s:%s" % (access_key_id, secret_access_key)
        signature = hmac.new(
            key=secret_access_key.encode(encoding),
            msg=msg.encode(encoding),
            digestmod=hashlib.sha256).digest()
        # Base64 encode the signature
        signature = base64.b64encode(signature)
        LOG.debug("Signature: %s" % signature.decode(encoding))
        return signature.decode(encoding)

    def ensure_signature_in_header(self, api_key, secret_key):
        signature = self.get_signature(access_key_id=api_key, secret_access_key=secret_key)
        self._headers = {'Authorization': 'Basic %s:%s' % (api_key, signature)}
        self._headers.update(self._content_type_json)

    
    def get_api_url(self, logtype):
        if logtype == LOG_TYPE_ADMIN:
            return ADMINEVENT_API
        else:
            return ACCESSLOG_API

    def get_logs(self, drpc_args, logtype=LOG_TYPE_EVENT, output=sys.stdout):
        global line_count
        scroll_id = None
        try:
            # Fetches the logs for given drpc args
            u = self.get_api_url(logtype)
            api_url = u.format(config.base_url, self._api_ver)

            self.ensure_signature_in_header(api_key=config.eaa_api_key, secret_key=config.eaa_api_secret)
            LOG.debug("request headers: %s"  % self._headers)
            resp = requests.post(
                api_url,
                data=drpc_args,
                headers=self._headers,
                allow_redirects=False
            )

            if resp.status_code != requests.codes.ok:
                LOG.error("Invalid API response status code: %s" % resp.status_code)
                return None

            resj = resp.json()
            LOG.debug("JSON> %s" % resj)

            if 'message' in resj:
                # Get msg and scroll_id based on the type of logs
                # Since it is two different API in the back-end
                if config.log_type == LOG_TYPE_EVENT:
                    msg = resj.get('message')[0][1]
                    scroll_id = msg.get('scroll_id')
                elif config.log_type == LOG_TYPE_ADMIN:
                    msg = resj.get('message')
                    if 'scroll_id' in msg.get('metadata'):
                        scroll_id = msg.get('metadata').get('scroll_id')

                LOG.debug("scroll_id: %s" % scroll_id)
                count = 0

                if config.log_type == LOG_TYPE_EVENT:
                    for timestamp, response in six.iteritems(msg):
                        try:
                            if not timestamp.isdigit():
                                LOG.debug("Ignored timestamp '%s': %s" % (timestamp, response))
                                continue
                            LOG.debug("flog is %s" % type(response['flog']).__name__)
                            LOG.debug("Scanned timestamp: %s" % timestamp)
                            local_time = datetime.fromtimestamp(int(timestamp)/1000)
                            if isinstance(response, dict) and 'flog' in response:
                                line = "%s\n" % ' '.join([local_time.isoformat(), response['flog']])
                                out.write(line.encode("utf8"))
                                LOG.debug("### flog ## %s" % response['flog'])
                                line_count += 1
                                count += 1
                        except Exception:
                            LOG.exception("Error parsing access log line")
                elif config.log_type == LOG_TYPE_ADMIN:
                    for item in msg.get('data'):
                        try:
                            local_time = datetime.fromtimestamp(int(item.get('ts')/1000))
                            line = u"{},{}\n".format(local_time.isoformat(), item.get('splunk_line'))
                            out.write(line.encode("utf8"))
                            line_count += 1
                            count += 1
                        except Exception as e:
                            LOG.exception('Error parsing admin log line: %s, content: %s' % (e, item.get('splunk_line')))

            else:
                LOG.error('Error: no data(message) in response.')
                LOG.error(drpc_args)
                LOG.error(json.dumps(resj))
            resp.close()
        except Exception as e:
            if "resp" in locals():
                LOG.debug("resp.status_code %s" % resp.status_code)
                LOG.debug("resp.text %s" % resp.text)
            LOG.error(drpc_args)
            LOG.exception("Exception in get_logs")
        return scroll_id


def log_level():
    if config.debug:
        return logging.DEBUG
    elif config.verbose:
        return logging.INFO
    else:
        return logging.ERROR


def date_boundaries():
    # end time in milliseconds, now minus collection delay
    ets = int(time.mktime(time.localtime()) * 1000 - (collection_delay_minutes * 60 * 1000))
    if not config.tail and config.end:
        ets = config.end * 1000
    # start time in milliseconds: end time minus poll interval
    sts = int(ets - (poll_interval_sec * 1000))
    if not config.tail and config.start:
        sts = config.start * 1000
    return ets, sts


def exit_gracefully(signum, frame):
    LOG.info("Stop due to SIGTERM or SIGINT signal received")
    stop_event.set()


if __name__ == "__main__":

    logging.basicConfig(filename=log_file, level=log_level(),
        format='%(asctime)s [%(levelname)s] %(threadName)s %(message)s')

    signal.signal(signal.SIGTERM, exit_gracefully)
    signal.signal(signal.SIGINT, exit_gracefully)
    etl = Etl();

    LOG.debug("Python %s" % platform.python_version())
    LOG.info("PID: %s" % os.getpid())
    LOG.info("Poll interval: %s seconds" % poll_interval_sec)

    if config.output is None:
        out = sys.stdout
    else:
        LOG.info("Output file: %s" % config.output)
        out = open(config.output, 'w+')

    try:
        while True:
            ets, sts = date_boundaries()
            s = time.time()
            LOG.info("Fetching log[%s] from %s to %s..." % (config.log_type, sts, ets))
            if config.log_type in (LOG_TYPE_ADMIN, LOG_TYPE_EVENT):
                # Use scroll paging
                drpc_args = '{"sts":'+ str(sts) + ',"ets":'+ str(ets) + \
                            ',"metrics":"logs","es_fields":"flog","limit":"1000","sub_metrics":"scroll","source": "%s"}' % SOURCE
                scroll_id = etl.get_logs(drpc_args, config.log_type, out)
                # Check for scroll_id to issue another request
                while (scroll_id != None):
                    drpc_args = '{"sts":'+ str(sts) +',"ets":'+ str(ets) + \
                    ',"metrics":"logs","es_fields":"flog","limit":"1000","sub_metrics":"scroll","source":"' + SOURCE + '","scroll_id":"'+scroll_id+'"}'
                    scroll_id = etl.get_logs(drpc_args, config.log_type, out)
                out.flush()
            else:
                raise Exception("Not supported log type: %s" % config.type)
            if not config.tail:
                break
            else:
                elapsed = time.time() - s
                LOG.debug("Now waiting %s seconds..." % (poll_interval_sec - elapsed))
                stop_event.wait(poll_interval_sec - elapsed)
                if stop_event.is_set():
                    break
    except Exception as e:
        LOG.exception("General exception")
    finally:
        if out is not None and out != sys.stdout:
            LOG.debug("Closing output file...")
            out.close()
        LOG.info("%s log lines were fetched." % line_count)

# end of file